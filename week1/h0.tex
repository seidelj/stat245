\documentclass{tufte-book}

\usepackage{amsmath, amsthm}
\usepackage{graphicx}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
\graphicspath{{graphics/}}

\title{STAT  245\\Homework 0}
\author{Joe Seidel}
\date{\today}

\input{../preamble.tex}

\begin{document}

\maketitle
\pagenumbering{gobble}
\newpage
\pagenumbering{arabic}

\subsection{1. Moments of Poisson Distribution}
Let $X$ be a random variable with a Poisson distribution.  Find $E(X^4)$.

One way to this using the formula

\[ E(X^4) = \sum_k x^4 \Pr\{X=k\}. \]

Observe \marginnote{\href{https://en.wikipedia.org/wiki/Stirling_numbers_of_the_second_kind}{Stirling numbers of the second kind}}
\[ x^4 = x+ 7x(x-1) + 6x(x-1)(x-2) + x(x-1)(x-2)(x-3). \]

We can derive each summation term individually.
\begin{align*}
E(X^4) &= \sum_x x^4 \Pr\{X=x\}\\
&= \sum_x x\Pr\{X=x\} + \sum_x 7x(x-1)\Pr\{X=x\} \\
&+ \sum_x 6x(x-1)(x-2)\Pr\{X=x\}\\
&+ \sum_x x(x-1)(x-2)(x-3) \Pr\{X=x\} .  \\
\end{align*}

\begin{align*}
\sum_x x\Pr\{X=x\} &= \lambda
\end{align*}

\begin{align*}
\sum_x 7x(x-1)\Pr\{X=x\} &= \sum_x 7x(x-1) e^{-\lambda}\frac{\lambda^x}{x!}\\
&=7e^{-\lambda} \sum_x x(x-1) \frac{\lambda^x}{x(x-1)(x-2)!}\\
&=7e^{-\lambda} \lambda^2 \sum_x \frac{\lambda^{x-2}}{(x-2)!}\\
&=7e^{-\lambda} \lambda^2 e^{\lambda}\\
&=7\lambda^2
\end{align*}

Using a similiar method, find


\[ \sum_x 6x(x-1)(x-2)\Pr\{X=x\} = 6\lambda^3 \]
and
\[ \sum_x x(x-1)(x-2)(x-3) \Pr\{X=x\} = \lambda^4. \]

Combining the results

\[ E(X^4) = \lambda + 7\lambda^2 + 6\lambda^3 + \lambda^3. \]


\subsection{2. Poisson- and $\chi^2$-tails}
For $\lambda > 0$, let $X_{\lambda}$ be a discrete random variable with a Poisson distribution with expected value $\lambda$.  For (integer) $d \in \mathbb{N}$, let $Y_d$ by a continuous random variable with a $\chi^2$-distribution with $d$ degrees of freedom.  In other words, the distribution of $Y_d$ has the probability density function

\[ f_{\chi^2_d}(y) = \frac{1}{2^{\frac{d}{2}}\Gamma(\frac{d}{2})}y^{\frac{d}{2}-1} e^{\frac{-y}{2}}, / y \geq 0 \]

where $\Gamma(.)$ is the Gamma-function which satisfies $\Gamma(n) = (n-1)!$ for $n \in \mathbb{N}$.  Show that for all $\lambda > 0$ and all (integer) $c \in \mathbb{N}$,

\[ \Pr\{X_{\lambda} \geq c+1\} = \Pr\{0 \leq Y_{2(c+1)} \leq 2\lambda\} = \int_0^{2\lambda}f_{\chi^2_{2(c+1)}}(y) dy. \]

First observe

\[ \Pr\{X_{\lambda} \geq c+1\} = 1-\sum_{k=0}^c e^{-\lambda}\frac{\lambda^k}{k!} \]

whose derivative is just Poisson density

\[ \frac{d}{d\lambda}\Pr\{X_{\lambda} \geq c+1\}= \Pr\{X=c\} = e^{-\lambda} \frac{\lambda^c}{c!}. \]

Next observe

\[ \Pr\{0 \leq Y_{2(c+1)} \leq 2\lambda\} = \int_0^{2\lambda} \frac{1}{2^{c+1} c!}y^c e^{-\frac{y}{2}} \]

whose derivative is

\begin{align*}
\pdv{}{\lambda} \Pr\{0 \leq Y_{2(c+1)} \leq 2\lambda\} &= \pdv{}{\lambda} \frac{\Gamma(c+1) - \Gamma(c+1, \lambda)}{c!} \\
&= e^{-\lambda} \frac{\lambda^c}{c!} \\
\end{align*}

Hence $\pdv{}{\lambda} \Pr\{0 \leq Y_{2(c+1)} \leq 2\lambda\} = \pdv{}{\lambda}\Pr\{X_{\lambda} \geq c+1\}$ which implies
\[ \Pr\{X_{\lambda} \geq c+1\} = \Pr\{0 \leq Y_{2(c+1)} \leq 2\lambda\}. \]

\subsection{3. Approximation to Binomial probabilities}
Let $X$ be distributed according to a Binomial$(n,p)$ distribution.  We are interested in the probability $\Pr(X=k)$ for

\begin{enumerate}
\item $n = 7, \ p=0.3, \ k=3$;

The binomial probability
\[ \Pr\{X=3\} = \binom{7}{3} .3^3 (1-.3)^4 = .2268. \]

The Normal Distribution approximation\marginnote{P.187 in Rice has a nice explanation if this} with $E(X) = np$ and $\Var(X) = np(1-p)$.

\begin{align*}
\Pr\{ X \geq 3 \} &= \Pr\{ \frac{X - 2.1}{\sqrt{1.47}} \leq \frac{3-2.1}{\sqrt{1.47}} \} \\
&\approx  1 - \Phi(0.742) \\
&= .249
\end{align*}

The Poisson approximation $\lambda = np$.

\[ \Pr\{X = 3\} = e^{-2.1} \frac{2.1^3}{3!} = .189 \]

\item $n=40, \ p=0.4, \ k=11$;

Binomial $=.0357$, Normal approximation $=0.035$, and Poisson $=0.0495$.

\item $n=400, \ p=.0025, \ k=2$;

Binomial $=.18417$, Normal approximation $=.2419$, and Poisson $=.1839$.

\end{enumerate}

The Poisson is a good approximation when $p$ is small and $n$ is large.  The Normal is a good approximation when $n$ is large and $p$ is close to $\frac{1}{2}$, i.e. the binomial distribution is symmetric.


\subsection{4. Conditional distributions in Poisson process}

Let $(X_t)_{t\geq 0}$ be a Possion process, and let
\[ T_1 = \min\{ t> 0: \ X_t \geq 1 \} \]
be the time to the first event.

\begin{enumerate}

\item Find the conditional distibution of $X_s$ given $X_t=n$ for fixed time points $t>s>0$ and integer $n \in \mathbb{N}$.

The coniditional distributio is given
\[ \Pr(X_s \ | \ X_t = n) = \frac{\Pr(X_s \cap X_t)}{\Pr(X_t=n)}. \]

Note that
\[ \Pr(X_s \cap X_t) = \Pr(X_s = x \cap X_t-X_s=n-x) \]
where $X_s$ and $X_t - X_s$ are independent of each other.

Then

\begin{align*}
\Pr(X_s \ | \ X_t = n) &= \frac{ e^{-\lambda s} \frac{(\lambda s)^x}{x!} \cdot e^{-\lambda(t-s)} \frac{[\lambda(t-s)]^{n-x}}{(n-x)!}}{e^{-\lambda t}\frac{(\lambda t)^n}{n!}}\\
&= \frac{n!}{x!(n-x)!} \cdot \frac{e^{-\lambda s} e^{-\lambda(t-s)} (\lambda s)^x [(t-s)\lambda]^{n-x}}{e^{-\lambda t} (\lambda t)^n} \\
&= \binom{n}{x} \frac{s^x (t-s)^{n-x}}{t^x \cdot t^{n-x}}\\
&= \binom{n}{x} \big(\frac{s}{t}\big)^x \big(1-\frac{s}{t}\big)^{n-x}\\
\end{align*}

\item Show that the conditional distribution of $T_1$ given $X_t=1$ is the uniform distribution on the interval $(0, t]$.

Consider $\Pr\{T_1 > s \ | \ X_t=1\}$ for $0<s<t$.

\begin{align*}
\Pr\{T_1 > s \ | \ X_t=1\} &= \frac{ \Pr\{ 0\text{ events in } (0,s] \cap 1 \text{ event in }(s,t]\}}{\Pr\{X_t=1\}}\\
&= \frac{ e^{-\lambda s} \cdot e^{-\lambda(t-s)} \lambda(t-s)}{e^{-\lambda t}\lambda t} \\
&= \frac{t-s}{t}
\end{align*}

Then
\[ \Pr\{T_1 \leq s \ | \ X_t=1\} = 1-\Pr\{T_1 > s \ | \ X_t=1\} = \frac{s}{t}. \]

Taking the deritive of the above equation results in

\[ \Pr\{T_1 = s \ | \ X_t=1\} = \frac{1}{t}. \]

\end{enumerate}

\subsection{5. Data from Poisson process}
A detector counts the number of particles emmoted from a radioactive source over the couse of 10-second intervals.  For $180$ such $10$-second intervals, the following counts were observed:

\begin{table}[H]
\centering
\begin{tabular}{cc}
Count & \# Itervals \\ \hline
$0$   & $23$        \\
$1$   & $77$        \\
$2$   & $34$        \\
$3$   & $26$        \\
$4$   & $13$        \\
$5$   & $7$
\end{tabular}
\end{table}

This table states, for example, that in 34 of the 10-second intervals a count of 2 was recorded.  Sometimes, however, the detector did not function properly and recorded counts over intervals of length 20 seconds.  This happened 20 times and recorded counts are

\begin{table}[H]
\centering
\begin{tabular}{cc}
Count & \# Itervals \\ \hline
$0$   & $2$        \\
$1$   & $4$        \\
$2$   & $9$        \\
$3$   & $5$        \\
\end{tabular}
\end{table}

Assume a Poisson process model for the particle emission process.  Let $\lambda > 0$ (time unit = $1$ sec.) be the unknown rate of the Poisson process.

\begin{enumerate}

\item Formulate an appropriate likelihood function for the described scenario and derive the maximum likelihood estimator for $\hat{\lambda}$ of the rate $\lambda$.  Compute $\hat{\lambda}$ for the above data.

First observe
\[ \Pr\{X=x\} = e^{-\lambda} \frac{\lambda^x}{x!} \]

then
\[ \text{lik}(\lambda) = \prod_{i=1}^n e^{-\lambda} \frac{\lambda^x_i}{x_i!}  \]

and the log is
\begin{align*}
l(\lambda) &= \sum_{i=1}^n(-\lambda + X_i\log \lambda - \log(X_i) \\
&= -n\lambda + \log\lambda \sum_{i=1}^n X_i - \sum_{i=1}^n \log X_i!.\\
\end{align*}

Setting $l'(\lambda)$ to zero gives

\[l'(\lambda) = -n + \frac{1}{\lambda}\sum{i=1}^n X_i = 0 \]

\[ \hat{\lambda} = \frac{1}{n}\sum_{i=1}^n X_i = \overline{X}. \]

That data observes $347$ occurances over $2200$ seconds which can be use to compute
\[ \hat{\lambda} = \frac{347}{2200} = .1577. \]

\item What approximation to the distribution of $\hat{\lambda}$ does the central limit theorem suggest\marginnote{Explanation of this in Rice p.262}?

Let
\[ S=X_1 + X_2 \]
and $\hat{\lambda}=\frac{s}{n}$ is a random variable.

\[ \Pr\{\hat{\lambda}=v \} = \Pr\{ s=nv \} = e^{-n\lambda_0}\frac{(n\lambda_0)^{nv}}{(nv)!} \]

for $v$ such that $nv$ is a nonnegative integer.

Since $S \sim \text{Pois}(n\lambda_0)$
\[ E(\hat{\lambda}) = frac{1}{n}E(S) = \lambda_0 \]
and
\[ \Var(\hat{\lambda}) = \frac{1}{n^2} \Var(S) = \frac{\lambda_0}{n}.\]

Since $E(\hat{\lambda}) = \lambda_0$, $\hat{\lambda}$ is unbiased and centered at $\lambda_0$ with standard error

\[ \sigma_{\hat{\lambda}} = \sqrt{\frac{\lambda_0}{n}}.\]

The standard error can be estimated

\[ s_{\hat{\lambda}} = \sqrt{\frac{\hat{\lambda}}{n}} \]

therefore $\hat{\lambda} \sim N(\lambda_0, s_{\hat{\lambda}})$.
\end{enumerate}

\end{document}
\grid
