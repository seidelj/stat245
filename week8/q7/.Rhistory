lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=30
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=30
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=30
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 10000
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 10000
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 10000
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
# Simulation to compare
# CI approximation (binomial)
# Wald, Wilson, Arcsin transformation
nsims = 100
n=150
p=.1
alpha=.05
z = qnorm(1-alpha/2)
samples = rbinom(nsims, size=n, p=p)
p.hats = samples/n
lower.wald = p.hats - qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
upper.wald = p.hats + qnorm(1-alpha/2)*sqrt( (p.hats*(1-p.hats)) /n)
lower.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) - sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
upper.wilson = (p.hats + (z^2)/(2*n))/(1+(z^2)/n) + sqrt( (p.hats*(1-p.hats))/n*z^2 + (z^4)/(4*n^2))/(1 + (z^2)/n)
lower.arcsin = sin(asin(sqrt(p.hats)) - z/(2*sqrt(n)))^2
upper.arcsin = sin(asin(sqrt(p.hats)) + z/(2*sqrt(n)))^2
mean(lower.wald <= p & upper.wald >= p)
mean(lower.wilson <= p & upper.wilson >= p)
mean(lower.arcsin <= p & upper.arcsin >= p)
qnrom(8/4
)
qnorm(2)
qnorm(2)
qnorm(-2/3)
qnorm(.2)
-2/3
qnorm(-.6667)
pnorm(2)
pnrom(6/4)
pnorm(6/4)
pnorm(0) - pnorm(-2/3)
pnorm(-1.5/sqrt(7.56)) - pnorm(-3.5/sqrt(7.56))
qgamma(0.5, shape=v/2, scale = 2)   # check that the limits "straddle" the median
qgamma(0.5, shape=v/2, scale = 2)   # check that the limits "straddle" the median
qgamma(0.5, shape=v/2, scale = 2)   # check that the limits "straddle" the median
source('~/chisquareintervals.R')
require("nleqslv")
v <- 10          # assign the degrees of freedom
CL<- 0.9                 # assign the desired confidence level for the C.I.
conf<- function(x) {
y<- numeric(2)
y[1]<- dgamma(x[1], shape=v/2, scale = 2)- dgamma(x[2], shape=v/2, scale = 2)
y[2]<- CL-pgamma(x[2], shape=v/2, scale = 2) + pgamma(x[1], shape=v/2,  scale = 2)
y
}
eL<- qgamma((1-CL)/2, shape=v/2, scale=2)
eU<- qgamma((1+CL)/2, shape=v/2, scale=2)
xstart<- c(eL,eU)      # the starting values are the equal-tails cut-offs
# eL may need to be reduced in value for very small degrees of freedom
nleqslv(xstart, conf, control=list(btol=.001))$x
qgamma(0.5, shape=v/2, scale = 2)   # check that the limits "straddle" the median
require("nleqslv")
v <- 10          # assign the degrees of freedom
CL<- 0.9                 # assign the desired confidence level for the C.I.
conf<- function(x) {
y<- numeric(2)
y[1]<- dgamma(x[1], shape=v/2, scale = 2)- dgamma(x[2], shape=v/2, scale = 2)
y[2]<- CL-pgamma(x[2], shape=v/2, scale = 2) + pgamma(x[1], shape=v/2,  scale = 2)
y
}
eL<- qgamma((1-CL)/2, shape=v/2, scale=2)
eU<- qgamma((1+CL)/2, shape=v/2, scale=2)
xstart<- c(eL,eU)      # the starting values are the equal-tails cut-offs
# eL may need to be reduced in value for very small degrees of freedom
nleqslv(xstart, conf, control=list(btol=.001))$x
qgamma(0.5, shape=v/2, scale = 2)   # check that the limits "straddle" the median
require("nleqslv")
v <- 10          # assign the degrees of freedom
CL<- 0.9                 # assign the desired confidence level for the C.I.
conf<- function(x) {
y<- numeric(2)
y[1]<- dgamma(x[1], shape=v/2, scale = 2)- dgamma(x[2], shape=v/2, scale = 2)
y[2]<- CL-pgamma(x[2], shape=v/2, scale = 2) + pgamma(x[1], shape=v/2,  scale = 2)
y
}
eL<- qgamma((1-CL)/2, shape=v/2, scale=2)
eU<- qgamma((1+CL)/2, shape=v/2, scale=2)
xstart<- c(eL,eU)      # the starting values are the equal-tails cut-offs
# eL may need to be reduced in value for very small degrees of freedom
nleqslv(xstart, conf, control=list(btol=.001))$x
qgamma(0.5, shape=v/2, scale = 2)   # check that the limits "straddle" the median
require("nleqslv")
v <- 10          # assign the degrees of freedom
CL<- 0.9                 # assign the desired confidence level for the C.I.
conf<- function(x) {
y<- numeric(2)
y[1]<- dgamma(x[1], shape=v/2, scale = 2)- dgamma(x[2], shape=v/2, scale = 2)
y[2]<- CL-pgamma(x[2], shape=v/2, scale = 2) + pgamma(x[1], shape=v/2,  scale = 2)
y
}
eL<- qgamma((1-CL)/2, shape=v/2, scale=2)
eU<- qgamma((1+CL)/2, shape=v/2, scale=2)
xstart<- c(eL,eU)      # the starting values are the equal-tails cut-offs
# eL may need to be reduced in value for very small degrees of freedom
nleqslv(xstart, conf, control=list(btol=.001))$x
qgamma(0.5, shape=v/2, scale = 2)   # check that the limits "straddle" the median
v <- 10          # assign the degrees of freedom
CL<- 0.9                 # assign the desired confidence level for the C.I.
conf<- function(x) {
y<- numeric(2)
y[1]<- dgamma(x[1], shape=v/2, scale = 2)- dgamma(x[2], shape=v/2, scale = 2)
y[2]<- CL-pgamma(x[2], shape=v/2, scale = 2) + pgamma(x[1], shape=v/2,  scale = 2)
y
}
eL<- qgamma((1-CL)/2, shape=v/2, scale=2)
eU<- qgamma((1+CL)/2, shape=v/2, scale=2)
xstart<- c(eL,eU)      # the starting values are the equal-tails cut-offs
# eL may need to be reduced in value for very small degrees of freedom
nleqslv(xstart, conf, control=list(btol=.001))$x
qgamma(0.5, shape=v/2, scale = 2)   # check that the limits "straddle" the median
v <- 10          # assign the degrees of freedom
CL<- 0.9                 # assign the desired confidence level for the C.I.
conf<- function(x) {
y<- numeric(2)
y[1]<- dgamma(x[1], shape=v/2, scale = 2)- dgamma(x[2], shape=v/2, scale = 2)
y[2]<- CL-pgamma(x[2], shape=v/2, scale = 2) + pgamma(x[1], shape=v/2,  scale = 2)
y
}
eL<- qgamma((1-CL)/2, shape=v/2, scale=2)
eU<- qgamma((1+CL)/2, shape=v/2, scale=2)
xstart<- c(eL,eU)      # the starting values are the equal-tails cut-offs
# eL may need to be reduced in value for very small degrees of freedom
nleqslv(xstart, conf, control=list(btol=.001))$x
qgamma(0.5, shape=v/2, scale = 2)   # check that the limits "straddle" the median
v <- 10          # assign the degrees of freedom
CL<- 0.9                 # assign the desired confidence level for the C.I.
conf<- function(x) {
y<- numeric(2)
y[1]<- dgamma(x[1], shape=v/2, scale = 2)- dgamma(x[2], shape=v/2, scale = 2)
y[2]<- CL-pgamma(x[2], shape=v/2, scale = 2) + pgamma(x[1], shape=v/2,  scale = 2)
y
}
eL<- qgamma((1-CL)/2, shape=v/2, scale=2)
eU<- qgamma((1+CL)/2, shape=v/2, scale=2)
xstart<- c(eL,eU)      # the starting values are the equal-tails cut-offs
# eL may need to be reduced in value for very small degrees of freedom
nleqslv(xstart, conf, control=list(btol=.001))$x
qgamma(0.5, shape=v/2, scale = 2)   # check that the limits "straddle" the median
insall.packages(nleqslv)
install.packages("nleqslv")
require("nleqslv")
v <- 10          # assign the degrees of freedom
CL<- 0.9                 # assign the desired confidence level for the C.I.
conf<- function(x) {
y<- numeric(2)
y[1]<- dgamma(x[1], shape=v/2, scale = 2)- dgamma(x[2], shape=v/2, scale = 2)
y[2]<- CL-pgamma(x[2], shape=v/2, scale = 2) + pgamma(x[1], shape=v/2,  scale = 2)
y
}
eL<- qgamma((1-CL)/2, shape=v/2, scale=2)
eU<- qgamma((1+CL)/2, shape=v/2, scale=2)
xstart<- c(eL,eU)      # the starting values are the equal-tails cut-offs
# eL may need to be reduced in value for very small degrees of freedom
nleqslv(xstart, conf, control=list(btol=.001))$x
qgamma(0.5, shape=v/2, scale = 2)   # check that the limits "straddle" the median
qnorm(5)
qnorm(2)
dnorm(5)
dnorm(-5)
dnorm(0)
dnorm(0)
qnorm(.5
)
qnorm(.5)
pnorm(5)
pnorm(0)
qnorm(.5)
dbinom(0, 10, .5)
dbinom(1-, 10, .5)
dbinom(10, 10, .5)
qchisq(.025, 1)
qchisq(1-.025, 1)
qnorm(0)
dnorm(0)
pnorm(0)
pchisq(.025, 1)
pchisq(1-.025, 1)
pchisq(1-.025, 100)
pchisq(.025, 100)
qchisq(.025, 100)
qchisq(1-.025, 100)
dbinom(10, 10, .5)
qnorm(.025)
qchisq(.025)
qchisq(.025, 1)
qchisq(1-.025, 1)
pchisq(.000982, 1)
pchisq(5.02, 1)
dnorm(-5)
dnorm(1.96)
dnorm(1.95)
dnorm(0)
pnorm(0)
pnorm(1.96)
pnorm(-5)
pnorm(0)
require(stat)
require(stats)
require(graphics)
summary(anscombe)
summary(anscombe)
x <- anscombe
x
library(YaleToolkit)
install
install.packages(YaleToolkit)
install.packages('YaleToolkit')
# housing data analysis
#################
# download NewHaven.txt from chalk to your own computer
setwd("/Users/joseph/stat245/week8/q7")
# set up your own working directory, with NewHaven.txt in the same place
library(YaleToolkit)
# you may want to install this nice package
x <- dget("NewHaven.txt")
# read data
whatis(x)
dim(x)
names(x)
summary(x)
